{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a3e116",
   "metadata": {},
   "source": [
    "# ARIMA\n",
    "- Produces Crowd Predicitions based on weather and user selected location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd456dd",
   "metadata": {},
   "source": [
    "### Load the Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebb45c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX \n",
    "from pmdarima import auto_arima\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime,timedelta,date\n",
    "import holidays as hl\n",
    "\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "trim_date = pd.to_datetime('2025-09-30').to_datetime64()# The end of the dataset, shouldn't assume both actual end at this date for each location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e0fcfb",
   "metadata": {},
   "source": [
    "### Load the data set ensure both the dataframe date range and date are in correct format for ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "551ce9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auck_peds = pd.read_csv(\"data_weather/Final/Auckland_Pedestrian_Hourly.csv\")\n",
    "Dub_peds = pd.read_csv(\"data_weather/Final/Dublin_Pedestrian_Hourly.csv\")\n",
    "\n",
    "df = pd.concat([Auck_peds, Dub_peds],ignore_index=True)\n",
    "\n",
    "df['Date'] = df['Date'].apply(lambda x: pd.to_datetime(x).to_datetime64())\n",
    "df = df.sort_values(['Location_ID','Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6258390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['2021-01-01T00:00:00.000000000', '2021-01-02T00:00:00.000000000',\n",
       "        '2021-01-03T00:00:00.000000000', ...,\n",
       "        '2025-09-28T00:00:00.000000000', '2025-09-29T00:00:00.000000000',\n",
       "        '2025-09-30T00:00:00.000000000'], dtype='datetime64[ns]')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df['Date'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f310aff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[numpy.datetime64('2025-09-30T00:00:00.000000000')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[trim_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e120d01",
   "metadata": {},
   "source": [
    "### Main ARIMA model\n",
    "- Model creation\n",
    "- Data splitting\n",
    "- Fitting model\n",
    "- Creates pickel files for each location\n",
    "    - Need seperate pickel files for forecasting each location \n",
    "- ARMIA needs to have even spacing between dates\n",
    "    if gap then a fill in needs to be done for Y values(Dep Var) & Exog(or X Ind Vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca3ba8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\athar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\athar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\athar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\athar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"arima_models\", exist_ok=True) \n",
    "\n",
    "models = {}\n",
    "for loc in df['Location_ID'].unique():\n",
    "    sub = df[df['Location_ID'] == loc].set_index('Date') # Important for the ARIMA model to function \n",
    "    \n",
    "    y = sub['Avg_Daily_Pedestrian_Count'].asfreq('D').interpolate(method='linear') # D is daily, rate of change fill in\n",
    "    x = sub[['Holiday',\n",
    "                'Weather_Temperature_Avg',\n",
    "                'Weather_Wind_Speed_Avg',\n",
    "                'Weather_Precipitation_Sum',\n",
    "                'Weather_Relative_Humidity_Avg']].asfreq('D').interpolate(method='linear') # numeric only\n",
    "    \n",
    "    y = y[y.index <= trim_date] # will change depending on new datasets in the future\n",
    "    x = x[x.index <= trim_date] # will change depending on new datasets in the future\n",
    "    \n",
    "    # Auto-tune ARIMA parameters\n",
    "    stepwise = auto_arima(y, # Dep\n",
    "                          seasonal=True,\n",
    "                          m=7, # weekly pattern\n",
    "                          trace=False,\n",
    "                          error_action='ignore',\n",
    "                          suppress_warnings=True)\n",
    "    \n",
    "    # Fit SARIMA model\n",
    "    model = SARIMAX(endog=y, # Dep\n",
    "                    exog=x, # Indep\n",
    "                    order=stepwise.order,\n",
    "                    seasonal_order=stepwise.seasonal_order,\n",
    "                    enforce_stationarity=False, # Variance and trends aren't constant set to false\n",
    "                    enforce_invertibility=False)\n",
    "    results = model.fit(disp=False)\n",
    "    \n",
    "    # Save model\n",
    "    model_path = f\"arima_models/{loc}_arima.pkl\"\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "855471b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Open-Meteo API client with cache and retry on error # <--- this is from Open Meteo Api Docs\n",
    "cache_session = requests_cache.CachedSession('.amriacache', expire_after = 3600)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c57526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weather_Requester(lat:float,long:float) -> pd.DataFrame:\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\" # Histroical Data\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": long,\n",
    "        \"start_date\": '2025-09-30',\n",
    "        \"end_date\": (date.today()-timedelta(days=1)).strftime('%Y-%m-%d'),\n",
    "        \"daily\": [\"precipitation_sum\", \"temperature_2m_mean\", \"relative_humidity_2m_mean\", \"wind_gusts_10m_mean\"],\n",
    "        \"timezone\": \"America/New_York\",\n",
    "    }\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "    # Basically getting the data for the beginning of the trim point of Sep 30 2025 of the dataset to 1 day - current day   \n",
    "    dly = responses[0].Daily()\n",
    "\n",
    "    P1 = dly.Variables(0).ValuesAsNumpy() # Np array's \n",
    "    T1 = dly.Variables(1).ValuesAsNumpy()\n",
    "    R1 = dly.Variables(2).ValuesAsNumpy()\n",
    "    W1 = dly.Variables(3).ValuesAsNumpy()\n",
    "\n",
    "    url = \"https://seasonal-api.open-meteo.com/v1/seasonal\" # Future Data\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": long,\n",
    "        \"forecast_days\": 180,\n",
    "        \"timezone\": \"America/New_York\",\n",
    "        \"daily\": [\"temperature_2m_mean\", \"wind_speed_10m_mean\", \"precipitation_sum\", \"relative_humidity_2m_mean\"]\n",
    "    }\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "    dly = responses[0].Daily()\n",
    "\n",
    "    T2 = dly.Variables(0).ValuesAsNumpy()\n",
    "    W2 = dly.Variables(1).ValuesAsNumpy()\n",
    "    P2 = dly.Variables(2).ValuesAsNumpy()\n",
    "    R2 = dly.Variables(3).ValuesAsNumpy()\n",
    "\n",
    "    T = np.concatenate((T1,T2))\n",
    "    w = np.concatenate((W1,W2))\n",
    "    P = np.concatenate((P1,P2))\n",
    "    R = np.concatenate((R1,R2))\n",
    "    \n",
    "    # Build the final indep array, holiday and time will be added later\n",
    "    vstk = pd.DataFrame(data = np.vstack((T,w,P,R)).T,\n",
    "                        columns=['Weather_Temperature_Avg',\n",
    "                                 'Weather_Wind_Speed_Avg',\n",
    "                                 'Weather_Precipitation_Sum',\n",
    "                                 'Weather_Relative_Humidity_Avg'])\n",
    "\n",
    "    return vstk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556a44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Holidayer(df:pd.DataFrame,CCode:str) -> pd.DataFrame:\n",
    "    # Uses country code and each data to find holiday or not\n",
    "    df['Holiday'] = df['Date'].apply(lambda x: 1 if hl.country_holidays(country=CCode).get(x) != None else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ba835d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            predicted_mean\n",
      "2025-09-07     4604.594345\n",
      "2025-09-08     4682.669700\n",
      "2025-09-09     4434.228291\n",
      "2025-09-10     4534.068012\n",
      "2025-09-11     4926.406846\n",
      "...                    ...\n",
      "2026-04-19     4854.459888\n",
      "2026-04-20     4812.007898\n",
      "2026-04-21     4861.627022\n",
      "2026-04-22     4824.223852\n",
      "2026-04-23     4843.202247\n",
      "\n",
      "[229 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "loc = \"IRDUB_1\" # This was a location to be displayed to user\n",
    "with open(f\"arima_models/{loc}_arima.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f) # grab right pickel file\n",
    "\n",
    "d = datetime(2025,11,29).date()# User specfiies a date -- test\n",
    "w = Weather_Requester(-36.8485,174.7633) # Grab weather from past and for future\n",
    "w.insert(0,'Holiday',0)# Inserting these columns to match indep input\n",
    "w.insert(0,'Date',range(len(w))) # Use range to fill in date indexing numbers \n",
    "# Add in the date range from trim point 2025-09-30\n",
    "w['Date'] = w['Date'].apply(lambda x: datetime(2025,9,30).date() + timedelta(days=x))\n",
    "h = Holidayer(w,'IE') # Add in the holiday data\n",
    "h = h.set_index('Date').asfreq('D').interpolate(method='linear') # numeric only\n",
    "# Send to predict next set of days\n",
    "pred_mean = pd.DataFrame(model.get_forecast(exog=h,steps=len(h)).predicted_mean)\n",
    "print(pred_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c2abbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2025-09-07 00:00:00')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_meancp = pred_mean.copy()\n",
    "idx = pred_meancp.index[:1][0] # deaaling with timestamps\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0366f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2025-11-29 00:00:00')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = pd.Timestamp(d) # convert user specified date\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e36a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4632.594479413196]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to get the forecasted crowd number at a date for a lcoation\n",
    "[pred_meancp['predicted_mean'].loc[f]] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
